{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture_1_notes.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kgmYzHYGJpd",
        "colab_type": "text"
      },
      "source": [
        "These are my notes as I follow along the [first lecture of TensorFlow for Research.](https://www.youtube.com/watch?v=g-EvyKpZjmQ&list=PLQ0sVbIj3URf94DQtGPJV629ctn2c1zN-&index=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ksbXD-fN_cL",
        "colab_type": "text"
      },
      "source": [
        "First, I will have a code snippet to be able to run tensorboard on Google colab. If you are running this locally, you wont need to do this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyBfY-cjGZ-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "380a5414-55f5-4d54-c564-9180bcf45125"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-20 15:59:04--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.72.230.122, 52.22.145.207, 52.73.9.93, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.72.230.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13607069 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.4’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  12.98M  13.4MB/s    in 1.0s    \n",
            "\n",
            "2019-07-20 15:59:06 (13.4 MB/s) - ‘ngrok-stable-linux-amd64.zip.4’ saved [13607069/13607069]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "https://fe08302a.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZLBK_CIHDbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ZqRA9aHK74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a0f0521-98c9-4858-fc8d-57f24ac0384c"
      },
      "source": [
        "a = tf.add(2, 3)\n",
        "b = tf.add(3.0, 5.0)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Add_2:0\", shape=(), dtype=int32)\n",
            "Tensor(\"Add_3:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tRn4vaUHnrr",
        "colab_type": "text"
      },
      "source": [
        "The computation is not run yet, all we've done is defined the graph structure. As you can see in dtype, the nodes can infer their data types from their inputs. How do we get the value of a and b? With a **session**.\n",
        "\n",
        "A session gets all the resources in place (CPUs, GPUs ) to actually run the computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tWYbAD-HmFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77b3eccb-c2df-4cae-9f4b-2f885cccf7da"
      },
      "source": [
        "sess = tf.Session()\n",
        "print(sess.run(a))\n",
        "sess.close()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z7-hzwZIdBb",
        "colab_type": "text"
      },
      "source": [
        "What TF does here is to look at the \"a\" and will compute everything that it needs to get the value of a. As you can see, it doesn't need to compute the value of b.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "058ZOAHPIrJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f6e7a68-b995-4a75-d9b0-6a4763f100c3"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  print(sess.run(a))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hl2mN1qI8UD",
        "colab_type": "text"
      },
      "source": [
        "The above is equivalent to what we did before (sess = tf....)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQjHs9BzIuQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 2\n",
        "y = 3\n",
        "op1 = tf.add(x, y)\n",
        "op2 = tf.multiply(x, y)\n",
        "op3 = tf.pow(op1, op2)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  op3 = sess.run(op3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "660E2U1LJdI8",
        "colab_type": "text"
      },
      "source": [
        "Now TF will need to calculate op3. What does op3 depend on? op1 and op2, so now TF wil have to calculate everything we defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXkZsPbYJVBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "536073ab-35ba-4421-9823-934b4b5271da"
      },
      "source": [
        "op3, (x + y) ** (x * y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7776, 15625)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQmmwIjOKYMc",
        "colab_type": "text"
      },
      "source": [
        "You can pass a whole list of nodes you cant to compute and tensorflow will return a list of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL7S2PV4Jr-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0f0fefd-40c9-421c-c50c-1f002fe65f2e"
      },
      "source": [
        "x = 2\n",
        "y = 3\n",
        "op1 = tf.add(x, y)\n",
        "op2 = tf.multiply(x, y)\n",
        "useless = tf.multiply(x, op1)\n",
        "op3 = tf.pow(op1, op2)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  op3_run, useless_run = sess.run([op3, useless])\n",
        "\n",
        "print( op3_run, useless_run)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15625 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVPX5HsIKf-E",
        "colab_type": "text"
      },
      "source": [
        "The great thing about having subgraphs that we can explicitly run is that we can parallelize our code inmensely by telling TF to run subgraph 1 on the GPU 0, subgraph 1 on GPU 1, and so on. But we will see this with more detail a few weeks from now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHt75uYRK83j",
        "colab_type": "text"
      },
      "source": [
        "# What if you want more graphs?\n",
        "Try not to, lol. Just have disconnected subgraphs within one default graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LykzhwfKJzy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c17a3e04-054d-40b1-cd0a-582ad1035c09"
      },
      "source": [
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default():\n",
        "   x = tf.add(3, 5)\n",
        "    \n",
        "sess = tf.Session(graph=g)\n",
        "x_result = sess.run(x)\n",
        "sess.close()\n",
        "print(x_result)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TaiVSraMI8L",
        "colab_type": "text"
      },
      "source": [
        "Here we see how we would explicitly handle graphs, but usually we won't need to do this. But its brittle because you may do something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEW-s_pAMCqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = tf.Graph()\n",
        "\n",
        "#This will add an op to the DEFAULT graph, not g\n",
        "a = tf.constant(3)\n",
        "\n",
        "#This, instead, will do for g\n",
        "with g.as_default():\n",
        "  b = tf.constant(5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aPbsqH_Mwo0",
        "colab_type": "text"
      },
      "source": [
        "This is very prone to errors because you don't know which nodes belong to each graph and you can't mix and match. I you really want to do it, do it more explicitly but even better don't do it!it's not to do it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2MXI9HTNDea",
        "colab_type": "text"
      },
      "source": [
        "# Why graphs? \n",
        "\n",
        "\n",
        "*   Because it gives you explicit control on what gets ran.\n",
        "*   Breaks up computation into small, self contained units (more important for implementation than for the user).\n",
        "*   Makes it easier for distributed computation.\n",
        "*   Many common ML algorithms are usually represented as directed graphs, so it's easy to translate them into tensorflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBZqPaxfNs8q",
        "colab_type": "text"
      },
      "source": [
        "# The End"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLY_q_iZNvOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}